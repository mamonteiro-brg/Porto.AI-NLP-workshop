{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8295, 111, 8, 25, 166, 40, 638, 10, 436, 22, 265, 9, 621, 575, 1080, 4742, 1149, 15874, 6, 438, 8295, 13, 102, 388, 15, 90, 67, 7, 197, 8295, 8, 4, 270, 416, 23, 527, 6, 15874, 4891, 4, 1055, 742, 16, 8, 36, 1480, 6, 2124, 100, 543, 5, 645, 362, 6, 2912, 4, 49, 8, 15874, 976, 124, 20, 5, 8295, 80, 9, 100, 362, 543, 395, 61, 44, 20, 8295, 8, 16, 40, 1276, 42, 1436, 166, 415, 6, 888, 4, 116, 9, 40, 3089, 4, 303, 163, 16, 64, 772, 13, 94, 156, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# Having a look at the data\n",
    "print(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "for key, value in word_index.items():\n",
    "       index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bleached could mln at world as holding for include its i 3 start measures gnp 525 process ccb and nations bleached it 1985 do 000 april 0 a agreed bleached mln in ended cost cts must and ccb tenneco in winter 53 1 mln net diplomats and reorganization group 38 said 49 26 and plastics in this mln ccb field foreign is said bleached 10 3 group 26 38 producers had 4 is bleached mln 1 as equivalent not 145 world york and credits in 20 3 as permits in set board 1 share turnover it than growth pct dlrs\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([index_to_word[x] for x in x_train[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "y_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = max(y_train) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training Samples: 8982\n",
      "# of Test Samples: 2246\n",
      "# of Classes: 46\n"
     ]
    }
   ],
   "source": [
    "print('# of Training Samples: {}'.format(len(x_train)))\n",
    "print('# of Test Samples: {}'.format(len(x_test)))\n",
    "print('# of Classes: {}'.format(num_classes))\n",
    "# of Training Samples: 8982\n",
    "# of Test Samples: 2246\n",
    "# of Classes: 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we want to do!\n",
    "![this3](https://image.slidesharecdn.com/kpisummerschool2015wordembeddingsandneurallanguagemodeling1-150828091027-lva1-app6892/95/kpi-summer-school-2015-word-embeddings-and-neural-language-modeling-28-638.jpg?cb=1440753116)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 56\n"
     ]
    }
   ],
   "source": [
    "# Different input dimensions!\n",
    "print(len(x_train[0]), len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequence_len = 100\n",
    "\n",
    "# pad text sequences\n",
    "x_train = pad_sequences(x_train, maxlen=sequence_len)\n",
    "x_test = pad_sequences(x_test, maxlen=sequence_len)\n",
    "\n",
    "# pass labels to a fixed dimension\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     1 27595 28842     8    43    10   447     5    25   207   270\n",
      "     5  3095   111    16   369   186    90    67     7    89     5    19\n",
      "   102     6    19   124    15    90    67    84    22   482    26     7\n",
      "    48     4    49     8   864    39   209   154     6   151     6    83\n",
      "    11    15    22   155    11    15     7    48     9  4579  1005   504\n",
      "     6   258     6   272    11    15    22   134    44    11    15    16\n",
      "     8   197  1245    90    67    52    29   209    30    32   132     6\n",
      "   109    15    17    12]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/c/Users/ola/portoai-nlp/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Flatten\n",
    "\n",
    "num_words = 50000\n",
    "embedding_dim = 32\n",
    "\n",
    "input = Input(shape=(sequence_len,), name=\"words_idx\")\n",
    "x = Embedding(num_words, output_dim=embedding_dim)(input)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16)(x)\n",
    "output = Dense(len(y_train[0]), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![this4](https://image.slidesharecdn.com/kpisummerschool2015wordembeddingsandneurallanguagemodeling1-150828091027-lva1-app6892/95/kpi-summer-school-2015-word-embeddings-and-neural-language-modeling-28-638.jpg?cb=1440753116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model = Model([input], output)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look inside embeddings weights\n",
    "before_embeddings = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04601956, -0.01554308, -0.02021786, ...,  0.00869598,\n",
       "         -0.03045226,  0.04847017],\n",
       "        [ 0.02852594, -0.03818436,  0.02280318, ..., -0.0218235 ,\n",
       "         -0.01591026,  0.00840474],\n",
       "        [-0.01995652, -0.0424386 , -0.02714961, ...,  0.04274425,\n",
       "         -0.01718838,  0.04180943],\n",
       "        ...,\n",
       "        [ 0.02374537,  0.01440113, -0.04720635, ...,  0.01661057,\n",
       "         -0.0285208 , -0.03650192],\n",
       "        [-0.01787205,  0.01878113, -0.02329276, ...,  0.01984921,\n",
       "         -0.00031283,  0.02013868],\n",
       "        [-0.03198608,  0.02111074, -0.03449867, ...,  0.00050364,\n",
       "         -0.00879012,  0.04555333]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/c/Users/ola/portoai-nlp/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/2\n",
      "8083/8083 [==============================] - 12s 2ms/step - loss: 2.1331 - acc: 0.4678 - val_loss: 1.7271 - val_acc: 0.5539\n",
      "Epoch 2/2\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 1.4283 - acc: 0.6357 - val_loss: 1.5166 - val_acc: 0.6218\n",
      "2246/2246 [==============================] - 0s 43us/step\n",
      "Test loss: 1.5128490428041372\n",
      "Test accuracy: 0.6273374888956388\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04778003, -0.02283379, -0.00449974, ..., -0.01279756,\n",
       "         -0.01062095,  0.05110388],\n",
       "        [-0.02302335, -0.04233605,  0.04907309, ..., -0.05940785,\n",
       "         -0.00978484,  0.01989996],\n",
       "        [ 0.00742607, -0.01621205, -0.00214382, ...,  0.01920804,\n",
       "         -0.02073726,  0.02142042],\n",
       "        ...,\n",
       "        [ 0.02374537,  0.01440113, -0.04720635, ...,  0.01661057,\n",
       "         -0.0285208 , -0.03650192],\n",
       "        [-0.01787205,  0.01878113, -0.02329276, ...,  0.01984921,\n",
       "         -0.00031283,  0.02013868],\n",
       "        [-0.03198608,  0.02111074, -0.03449867, ...,  0.00050364,\n",
       "         -0.00879012,  0.04555333]], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look inside embeddings weights\n",
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04601956 -0.01554308 -0.02021786  0.0447003  -0.04753053 -0.01382623\n",
      " -0.02505436 -0.04954783 -0.01468536 -0.03577384 -0.03308809  0.04695566\n",
      "  0.00676578  0.03421665  0.04425024 -0.00800001 -0.02503148  0.04108813\n",
      "  0.04306828  0.00433546 -0.04491458  0.04180301  0.00239607 -0.00478263\n",
      "  0.0045232  -0.00864415  0.00921013  0.00267029  0.03739797  0.00869598\n",
      " -0.03045226  0.04847017]\n",
      "[ 0.04778003 -0.02283379 -0.00449974  0.0390374  -0.04742653  0.02518003\n",
      " -0.01547205 -0.04282432  0.01244631 -0.02246185 -0.03852264  0.04239924\n",
      " -0.01813188  0.02635528  0.03717105  0.03415433 -0.02073458  0.03327616\n",
      "  0.02164897 -0.02178071 -0.04624386  0.02622519 -0.01788031  0.01164822\n",
      " -0.03788704  0.01609039 -0.015049    0.024016    0.02950859 -0.01279756\n",
      " -0.01062095  0.05110388]\n"
     ]
    }
   ],
   "source": [
    "# first embedding\n",
    "print(before_embeddings[0][0])\n",
    "print(model.layers[1].get_weights()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03198608  0.02111074 -0.03449867  0.03452109 -0.04455796  0.02440829\n",
      " -0.04796584  0.04020821  0.03581233 -0.01820178  0.03445984 -0.03317568\n",
      "  0.00663571  0.01838228 -0.04200111 -0.03165336 -0.00038855 -0.03517633\n",
      " -0.0132449   0.00412346  0.02558391  0.03398455  0.00598979 -0.04673339\n",
      " -0.04224164 -0.00108529  0.01757446 -0.04237891 -0.01370193  0.00050364\n",
      " -0.00879012  0.04555333]\n",
      "[-0.03198608  0.02111074 -0.03449867  0.03452109 -0.04455796  0.02440829\n",
      " -0.04796584  0.04020821  0.03581233 -0.01820178  0.03445984 -0.03317568\n",
      "  0.00663571  0.01838228 -0.04200111 -0.03165336 -0.00038855 -0.03517633\n",
      " -0.0132449   0.00412346  0.02558391  0.03398455  0.00598979 -0.04673339\n",
      " -0.04224164 -0.00108529  0.01757446 -0.04237891 -0.01370193  0.00050364\n",
      " -0.00879012  0.04555333]\n"
     ]
    }
   ],
   "source": [
    "# last embedding\n",
    "print(before_embeddings[0][-1])\n",
    "print(model.layers[1].get_weights()[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
